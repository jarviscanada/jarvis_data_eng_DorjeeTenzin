{
  "metadata": {
    "name": "Hive Query Project",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \r\n# Quention 1: Load GS Data to HDFS\r\n\r\n## Create External Table `wdi_csv_text`\r\n```hive\r\nDROP TABLE IF EXISTS wdi_csv_text;\r\nCREATE EXTERNAL TABLE wdi_csv_text\r\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\r\nROW FORMAT DELIMITED FIELDS TERMINATED BY \u0027,\u0027 LINES TERMINATED BY \u0027\\n\u0027\r\nLOCATION \u0027hdfs:///user/tedor18/hive/wdi/wdi_csv_text\u0027;\r\n```\r\n\r\n## Load Data from `wdi_gs` to `wdi_csv_text`\r\n```hive\r\nINSERT OVERWRITE TABLE wdi_csv_text\r\nSELECT * FROM wdi_gs\r\n```\r\n\r\n## Check HDFS File Size\r\n```cmd\r\nhdfs dfs -ls -h /user/ewang/hive/wdi/wdi_csv_text\r\n```\r\n\r\n## Execute Query\r\n```hive\r\nSELECT count(countryName) FROM wdi_csv_text\r\n```\r\n- Run twice consecutively\r\n- Intial run: 13.40 s\r\n- Second run: 4.12 s\r\n\r\n## Clear File System Cache\r\n```cmd\r\necho 3 | sudo tee /proc/sys/vm/drop_caches\r\n```\r\n- Clear cache in both the master and worker nodes\r\n- Execute query again\r\n- Third run: 13.45 s\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DROP TABLE IF EXISTS wdi_csv_text;\r\nCREATE EXTERNAL TABLE wdi_csv_text\r\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\r\nROW FORMAT DELIMITED FIELDS TERMINATED BY \u0027,\u0027 LINES TERMINATED BY \u0027\\n\u0027\r\nLOCATION \u0027hdfs:///user/tedor18/hive/wdi/wdi_csv_text\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "INSERT OVERWRITE TABLE wdi_csv_text\r\nSELECT * FROM wdi_gs"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SELECT count(countryName) FROM wdi_csv_text"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n# Questions 2: Monitor Hadoop/Yarn Job\n- __Yarn Application Timer__: List of application executed through yarn currently and historically. Holds generic information such as individual containers used from the worker nodes \n- __Tez__: View Tez applications generated by Hive. Access each individual queries and view their respective mapper and reducer usage. "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n# Question 3: Hive Vs. Bash\n### Perform Row Count Using Bash\n```sh\ncd ~\nhdfs  dfs -get  hdfs:///user/tedor18/hive/wdi/wdi_csv_text .\ncd wdi_csv_text\n\n#calculate current directory size\ndu -ch .\n\n#clear fs cache\necho 3 | sudo tee /proc/sys/vm/drop_caches\n#bash row count\ndate +%s \u0026\u0026 cat * | wc \u0026\u0026 date +%s\n```\n- __Execution Time__: 31.0 s\n\n### Performance: Hive vs Bash\n- Hive is able to compute much faster than bash, because it leverages the file system caching which allows it to read from memory instead of disk.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh \ncd ~\nhdfs  dfs -get  hdfs:///user/tedor18/hive/wdi/wdi_csv_text .\ncd wdi_csv_text\n\n#calculate current directory size\ndu -ch .\n\n#clear fs cache\necho 3 | sudo tee /proc/sys/vm/drop_caches\n#bash row count\ndate +%s \u0026\u0026 cat * | wc \u0026\u0026 date +%s\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n# Question 4: Parsing Issue\n## Execute Following Query \n```hive \nSELECT distinct(indicatorcode)\nFROM wdi_csv_text\nORDER BY indicatorcode\nLIMIT 20;\n```\n- Parsing issue: contains invalid entires in the `inidicatorCode` column\n\n## Debug Table \n### Step 1: Create Debug Table \n```hive\nDROP TABLE IF EXISTS wdi_gs_debug;\nCREATE EXTERNAL TABLE wdi_gs_debug\n(line STRING)\nROW FORMAT DELIMITED LINES TERMINATED BY \u0027\\n\u0027\nLOCATION \u0027gs://jarvis_data_eng_dorjee/datasets/wdi_2016\u0027;\n```\n- Removed field delimiter \n\n### Step 2: Query Debug Table\n```hive \nSELECT * FROM wdi_gs_debug\nWHERE line like \"%\\(\\% of urban population\\)\\\"%\"\nLIMIT 20\n```\n- The parsing issue is noticable in the `indicatorName` column where there are `,` which is set as the delimiter for different values.\n\n## OpenCSV SerDe\n### Step 1: Create New External Table `wdi_opencsv_gs` in GS\n```hive\nDROP TABLE IF EXISTS wdi_opencsv_gs;\nCREATE EXTERNAL TABLE wdi_opencsv_gs\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\nLOCATION \u0027gs://jarvis_data_eng_dorjee/datasets/wdi_2016\u0027;\n```\n\n### Step 2: Create New External Table `wdi_opencsv_text` in HDFS\n```hive \nDROP TABLE IF EXISTS wdi_opencsv_text;\nCREATE EXTERNAL TABLE wdi_opencsv_text\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\nLOCATION \u0027hdfs:///user/tedor18/hive/wdi/wdi_opencsv_text\u0027;\n```\n\n### Step 3: Export and Overwrite data from GS to HDFS\n```hive \nINSERT OVERWRITE TABLE wdi_opencsv_text\nSELECT * FROM wdi_opencsv_gs\n```\n\n### Step 4: Query `wdi_opencsv_text`\n```hive \nSELECT distinct(indicatorcode) FROM wdi_opencsv_text\nLIMIT 20\n```\n\n### Step 5: Comparing Execution Time `LazySimpleSerDe` vs `OpenCSV SerDe`\n```hive \nSELECT count(countryName) FROM wdi_opencsv_text;\nSELECT count(countryName) FROM wdi_csv_text;\n```\n\n- `wdi_csv_text` is faster than `wdi_opencsv_text` because it uses `LazySimpleSerde` which is faster for dataset that\u0027s appropiately formatted. \n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SELECT distinct(indicatorcode)\nFROM wdi_csv_text\nORDER BY indicatorcode\nLIMIT 20;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DROP TABLE IF EXISTS wdi_gs_debug;\r\nCREATE EXTERNAL TABLE wdi_gs_debug\r\n(line STRING)\r\nROW FORMAT DELIMITED LINES TERMINATED BY \u0027\\n\u0027\r\nLOCATION \u0027gs://jarvis_data_eng_dorjee/datasets/wdi_2016\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SELECT * FROM wdi_gs_debug\r\nWHERE line like \"%\\(\\% of urban population\\)\\\"%\"\r\nLIMIT 20"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DROP TABLE IF EXISTS wdi_opencsv_gs;\r\nCREATE EXTERNAL TABLE wdi_opencsv_gs\r\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\r\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\r\nLOCATION \u0027gs://jarvis_data_eng_dorjee/datasets/wdi_2016\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DROP TABLE IF EXISTS wdi_opencsv_text;\r\nCREATE EXTERNAL TABLE wdi_opencsv_text\r\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\r\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\r\nLOCATION \u0027hdfs:///user/tedor18/hive/wdi/wdi_opencsv_text\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "INSERT OVERWRITE TABLE wdi_opencsv_text\r\nSELECT * FROM wdi_opencsv_gs"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SELECT distinct(indicatorcode) FROM wdi_opencsv_text\r\nLIMIT 20"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SELECT count(countryName) FROM wdi_opencsv_text;\r\nSELECT count(countryName) FROM wdi_csv_text;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n# Question 5: OpenCsvSerde Limitaion\n## Table Metadata \n```hive\nDESCRIBE FORMATTED wdi_opencsv_text;\nDESCRIBE FORMATTED wdi_csv_text;\n```\n- OpenCSVSerde will treat every field as String by default, as a result the `year` and `indicatorValue` are incorrectly typed\n\n## Create a View\n```hive\nDROP VIEW IF EXISTS wdi_opencsv_text_view;\nCREATE VIEW wdi_opencsv_text_view AS \nSELECT CAST(year AS INTEGER), countryName, countryCode, indicatorName, indicatorCode, CAST(indicatorValue AS FLOAT)\nFROM wdi_opencsv_text;\n```\n## Metadata\n```hive\nDESCRIBE FORMATTED wdi_opencsv_text_view;\n```"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DESCRIBE FORMATTED wdi_opencsv_text;\r\nDESCRIBE FORMATTED wdi_csv_text;"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DROP VIEW IF EXISTS wdi_opencsv_text_view;\r\nCREATE VIEW wdi_opencsv_text_view AS \r\nSELECT CAST(year AS INTEGER), countryName, countryCode, indicatorName, indicatorCode, CAST(indicatorValue AS FLOAT)\r\nFROM wdi_opencsv_text;"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DESCRIBE FORMATTED wdi_opencsv_text_view;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n# Question 6: 2015 Canada GDP Growth HQL\n## GDP Growth for Canada in 2015\n```hive \nSELECT year, countryName, indicatorValue\nFROM wdi_opencsv_text\nWHERE UPPER(countryName)\u003d\"CANADA\" AND indicatorCode\u003d\"NY.GDP.MKTP.KD.ZG\" AND YEAR\u003d\"2015\";\n```\n\n## Improvements\n- Could index/partition the table to improve the query performance \n"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SELECT year, countryName, indicatorValue\nFROM wdi_opencsv_text\nWHERE UPPER(countryname)\u003d\"CANADA\" AND indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\" AND YEAR\u003d\"2015\";\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n# Question 7: Hive Partitions\nUse paritions to optimize query performance \n## Create Partition Table\n```hive\nDROP TABLE IF EXISTS wdi_opencsv_text_partitions;\nCREATE EXTERNAL TABLE wdi_opencsv_text_partitions\n(countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nPARTITIONED BY (year INTEGER)\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\nLOCATION \u0027hdfs:///user/tedor18/hive/wdi/wdi_opencsv_text_partitions\u0027;\n```\n\n## Export and Overwite Data from `wdi_opencsv_text` to `wdi_opencsv_text_partitions`\n```hive\nSET hive.exec.dynamic.partition.mode\u003dnonstrict;\nSET hive.exec.max.dynamic.partitions.pernode\u003d100;\nFROM wdi_opencsv_text\nINSERT OVERWRITE TABLE wdi_opencsv_text_partitions \nPARTITION(year)\nSELECT countryName, countryCode, indicatorName, indicatorcode, indicatorValue, year;\n```\n\n## Number of Partitions (sub-directories)\n```sh\nhdfs dfs -count -h /user/tedor18/hive/wdi/wdi_opencsv_text_partitions \n```\n\n## GDP Growth for Canada in 2015 (paritioned ver.)\n```hive\nSELECT year, countryName, indicatorValue\nFROM wdi_opencsv_text_partitions\nWHERE UPPER(countryName)\u003d\"CANADA\" AND indicatorCode\u003d\"NY.GDP.MKTP.KD.ZG\" AND YEAR\u003d\"2015\";\n```\n- Significantly faster query\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DROP TABLE IF EXISTS wdi_opencsv_text_partitions;\r\nCREATE EXTERNAL TABLE wdi_opencsv_text_partitions\r\n(countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\r\nPARTITIONED BY (year INTEGER)\r\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\r\nLOCATION \u0027hdfs:///user/tedor18/hive/wdi/wdi_opencsv_text_partitions\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SET hive.exec.dynamic.partition.mode\u003dnonstrict;\nSET hive.exec.max.dynamic.partitions.pernode\u003d100;\nFROM wdi_opencsv_text\nINSERT OVERWRITE TABLE wdi_opencsv_text_partitions \nPARTITION(year)\nSELECT countryName, countryCode, indicatorName, indicatorCode, indicatorValue, year;"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nhdfs dfs -count -h /user/tedor18/hive/wdi/wdi_opencsv_text_partitions "
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SELECT year, countryName, indicatorValue\nFROM wdi_opencsv_text_partitions\nWHERE UPPER(countryName)\u003d\"CANADA\" AND indicatorCode\u003d\"NY.GDP.MKTP.KD.ZG\" AND YEAR\u003d\"2015\";"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n# Question 8: Columnar File Optimization\n\n## Create Parquet File \n```hive \nDROP TABLE IF EXISTS wdi_csv_parquet;\nCREATE EXTERNAL TABLE wdi_csv_parquet\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nSTORED AS PARQUET\nLOCATION \u0027hdfs:///user/tedor18/hive/wdi/wdi_csv_parquet\u0027;\n```\n## Load Data \n```hive\nFROM wdi_opencsv_gs\nINSERT OVERWRITE TABLE wdi_csv_parquet\nSELECT *;\n```\n\n## Compare TextFile and Parquet\n### File Size \n```sh\nhdfs dfs -du -s -h /user/tedor18/hive/wdi/wdi_opencsv_text;\nhdfs dfs -du -s -h /user/tedor18/hive/wdi/wdi_csv_parquet;\n```\n- parquet is significantly smaller \n\n### Runtime \n```hive\nSELECT count(countryName) FROM wdi_opencsv_text;\nSELECT count(countryName) FROM wdi_csv_parquet;\n```\n- Initial run are about same, however in subsequent runs, parquet is significantly faster\n\n### 2015 GDP Growth \n```hive\nSELECT year, countryName, indicatorValue\nFROM wdi_opencsv_text\nWHERE UPPER(countryName)\u003d\"CANADA\" AND indicatorCode\u003d\"NY.GDP.MKTP.KD.ZG\" AND YEAR\u003d\"2015\";\n```\n```hive\nSELECT year, countryName, indicatorValue\nFROM wdi_csv_parquet\nWHERE UPPER(countryName)\u003d\"CANADA\" AND indicatorCode\u003d\"NY.GDP.MKTP.KD.ZG\" AND YEAR\u003d\"2015\";\n```"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DROP TABLE IF EXISTS wdi_csv_parquet;\nCREATE EXTERNAL TABLE wdi_csv_parquet\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nSTORED AS PARQUET\nLOCATION \u0027hdfs:///user/tedor18/hive/wdi/wdi_csv_parquet\u0027;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "FROM wdi_opencsv_gs\nINSERT OVERWRITE TABLE wdi_csv_parquet\nSELECT *;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nhdfs dfs -du -s -h /user/tedor18/hive/wdi/wdi_opencsv_text;\nhdfs dfs -du -s -h /user/tedor18/hive/wdi/wdi_csv_parquet;"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SELECT year, countryName, indicatorValue\nFROM wdi_csv_parquet\nWHERE UPPER(countryName)\u003d\"CANADA\" AND indicatorCode\u003d\"NY.GDP.MKTP.KD.ZG\" AND YEAR\u003d\"2015\";"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Question 9: Highest GDP Growth For Each Country\n\n```hive\nSELECT a.indicatorValue as GDP_growth_value, a.year, a.countryName\nFROM wdi_csv_parquet a \nINNER JOIN\n(SELECT MAX(indicatorValue) as indicatorValue, countryName\nFROM wdi_csv_parquet\nWHERE indicatorCode \u003d \"NY.GDP.MKTP.KD.ZG\"\nAND indicatorValue \u003e 0.0\nGROUP BY countryName) b\nON  a.indicatorValue \u003d b.indicatorValue\nAND a.countryName \u003d b.countryName\n```\n- Spark was much faster than hive\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SELECT a.indicatorValue as GDP_growth_value, a.year, a.countryName\nFROM wdi_csv_parquet a \nINNER JOIN\n(SELECT MAX(indicatorValue) as indicatorValue, countryName\nFROM wdi_csv_parquet\nWHERE indicatorCode \u003d \"NY.GDP.MKTP.KD.ZG\"\nAND indicatorValue \u003e 0.0\nGROUP BY countryName) b\nON  a.indicatorValue \u003d b.indicatorValue\nAND a.countryName \u003d b.countryName"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n# Question 10: Sort GDP by Country and Year \n```hive\nSELECT countryName, year indicatorValue AS GDP_Growth \nFROM wdi_csv_parquet \nWHERE indicatorCode\u003d\"NY.GDP.MKTP.KD.ZG\"\nORDER BY countryName, year;\n```"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "SELECT countryName, year indicatorValue AS GDP_Growth \nFROM wdi_csv_parquet \nWHERE indicatorCode\u003d\"NY.GDP.MKTP.KD.ZG\"\nORDER BY countryName, year;"
    }
  ]
}